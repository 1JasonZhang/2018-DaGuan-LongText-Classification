# “达观杯”文本智能处理挑战赛
# 1.模型思路：
    训练集/测试集都包括了10W+的文章数据，两列属性：字的脱敏、词的脱敏。
    对于文本分类词向量化的选择，相比较于word2vec\LDA,TF-IDF在大数据集下表现更好
    理论上来说，应该对两列数据（字、词）都进行tf-idf，但是内存空间消耗巨大！！优先使用词列进行向量化
# 2.模型选择：LSTM+LR
    选择两种模型，对输出结果进行模型融合，可以选择并集或者交集，
    选择LSTM原因：①样本本身存在序列化的关系（上下文关联）
                 ②深度NN模型可以分批次持续训练，减少训练开销
    选择LR作为基准模型：由于样本维数高，单机处理难度大，对于ML模型来说，不能分批训练，开销特别大
    SVM由于核函数映射之后，给内存带来极大压力，效率不如LR/深度模型

    
