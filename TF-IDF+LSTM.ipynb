{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np,tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_csv_feather(path,path_new):\n",
    "    f = open(path)\n",
    "    reader = pd.read_csv(f, sep=',', iterator=True)\n",
    "    loop = True\n",
    "    chunkSize = 10000\n",
    "    chunks = []\n",
    "    while loop:\n",
    "        try:\n",
    "            chunk = reader.get_chunk(chunkSize)\n",
    "            chunks.append(chunk)\n",
    "        except StopIteration:\n",
    "            loop = False\n",
    "            print(\"Iteration is stopped.\")\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "    print(df.count())\n",
    "    feather.write_dataframe(df,path_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###测试集、训练集维数分别是（102277，3），（102277，4），需要先转化成feather文件，再进行批次读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_csv_feather(r\"D:\\Competition\\Daguan\\new_data\\train_set.csv\",r\"D:\\Competition\\Daguan\\new_data\\train_set.feather\")\n",
    "gen_csv_feather(r\"D:\\Competition\\Daguan\\new_data\\test_set.csv\",r\"D:\\Competition\\Daguan\\new_data\\test_set.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=feather.read_dataframe(r\"D:\\Competition\\Daguan\\new_data\\train_set.feather\")\n",
    "test=feather.read_dataframe(r\"D:\\Competition\\Daguan\\new_data\\test_set.feather\")\n",
    "#转化时列名出现乱码，修改即可\n",
    "train=train.rename(columns={'锘縤d':'id'})\n",
    "test=test.rename(columns={'锘縤d':'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(ngram_range=(1,2),min_df=3, max_df=0.9,use_idf=1,smooth_idf=1, sublinear_tf=1)\n",
    "train_word=tfidf.fit_transform(train['word_seg']).toarray()\n",
    "test_word=tfidf.transform(test['word_seg']).toarray()\n",
    "from sklearn import preprocessing\n",
    "ohe=preprocessing.OneHotEncoder(n_values=20)\n",
    "l=train['class']\n",
    "l=l.reshape(-1,1)\n",
    "train_l=ohe.fit_transform(l).toarray()\n",
    "train_l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####训练集train_word,train_l  测试集test_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_batch(data,label,batch_size):\n",
    "    row, col = data.shape\n",
    "    n = row // batch_size     \n",
    "    for i in range(n):\n",
    "        x = data[i * batch_size : (i + 1) * batch_size,:]     \n",
    "        y = label[i * batch_size : (i + 1) * batch_size,:] \n",
    "        yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_units = 256\n",
    "num_layer = 3\n",
    "input_size = 199\n",
    "time_step = 28\n",
    "total_steps = 150\n",
    "category_num = 20\n",
    "steps_per_validate = 50\n",
    "batch_size = tf.placeholder(tf.int32, [])\n",
    "keep_prob = tf.placeholder(tf.float32, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 5572])\n",
    "y_label = tf.placeholder(tf.float32, [None, 20])\n",
    "#每个样本按time_stepxinput_size输入LSTM网络\n",
    "x_shape = tf.reshape(x, [-1, time_step, input_size])\n",
    "#DroupoutWrapper防止过拟合\n",
    "from tensorflow.contrib.rnn import DropoutWrapper\n",
    "def cell(num_units):\n",
    "    cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=num_units)\n",
    "    return DropoutWrapper(cell, output_keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-53-5dbeb49f2af1>:13: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#三层LSTM\n",
    "cells = tf.nn.rnn_cell.MultiRNNCell([cell(num_units) for _ in range(num_layer)])\n",
    "#由于样本集比较大，设置batch_size=2000\n",
    "h0 = cells.zero_state(batch_size, dtype=tf.float32)\n",
    "output, hs = tf.nn.dynamic_rnn(cells, inputs=x_shape, initial_state=h0)\n",
    "#网络中每个样本最后一个时间序列的结果作为输出\n",
    "output = output[:, -1, :]\n",
    "# Output Layer，全连接层线性变换\n",
    "w = tf.Variable(tf.truncated_normal([num_units, category_num], stddev=0.1), dtype=tf.float32)\n",
    "b = tf.Variable(tf.constant(0.1, shape=[category_num]), dtype=tf.float32)\n",
    "y = tf.matmul(output, w) + b\n",
    "# Loss\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training= tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correction_prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_label, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction, tf.float32))\n",
    "\n",
    "saver=tf.train.Saver(max_to_keep=1)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(total_steps + 1):\n",
    "        for batch_x,batch_y in gen_batch(train_word,train_l,2000):\n",
    "            sess.run(training, feed_dict={x: batch_x, y_label: batch_y, keep_prob: 0.5, batch_size:2000})\n",
    "            if step % steps_per_validate == 0:\n",
    "                print('Train', step, sess.run(accuracy, feed_dict={x: batch_x, y_label: batch_y, keep_prob:0.5,\n",
    "                                                               batch_size:2000}))\n",
    "            saver.save(sess,r\"C:\\Users\\hp\\tfModels\\daguanLSTM.cpkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testshape=test.shape[0]\n",
    "with tf.Session() as sess2:\n",
    "    sess2.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess2,r\"C:\\Users\\hp\\tfModels\\daguanLSTM.cpkt\")\n",
    "    y_pred=sess2.run(y,feed_dict={x:test_word,keep_prob:0.5,batch_size:testshape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_pred=tf.argmax(y_pred,axis=1)\n",
    "with tf.Session() as result:\n",
    "    l=result.run(label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predict(testdata,y_pred):\n",
    "    user=pd.DataFrame(testdata['user_id'])\n",
    "    label=pd.DataFrame(y_pred)\n",
    "    u=pd.concat([user,label],axis=1).rename(columns={0:'label'})\n",
    "    r=u[u['label']==1]\n",
    "    id=r['user_id']\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id=get_predict(test,l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
